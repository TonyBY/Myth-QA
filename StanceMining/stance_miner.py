from distutils.command.build import build
from typing import List, Optional
from tqdm import tqdm
import pandas as pd
import os
import sys

from StanceDetection.stance_detector import StanceDetector
from Helper.utils import get_raw, read_jsonl, save_jsonl, build_claim, logger
from Helper.constants import CLAIM_CONSTRUCTOR
from IR.base import Retriever
from .base import StanceMiner

class EntityClaimStanceMiner(StanceMiner):
    """
    This class contains fuctions 
        to contruct claims using questions and corresponding distinct answers; 
        to retrieve relevent tweet for the claims; 
        to prediction relations between claims and their relevent tweets.

    Paras:
        machine_reader_results: List[dict]
            results generated by machine readers.
        retriever: Retriever
            a Retriver instance that is used to retrieve relenvent tweets for claims/premises.
        stance_detector_name: str
            a pretrained stance detection transformer name that is used to initiate a StanceDetector object.
        topk: int
            topk relevant tweets of a claim/premise to retrieve for stance detection.
        entity_claim_retrievals_path: str
            file path to save the retrieved tweets.
        entity_claim_stances_path: str
            file path to save the stance detected tweets.
    """
    def __init__(self, retriever: Retriever, stance_detector_name: str, topk: int = 100,
                 entity_claim_retrievals_path: Optional[str] = None,
                 entity_claim_stances_path: Optional[str] = None,):
        
        self.retriever = retriever
        self.stance_detector_name = stance_detector_name
        self.entity_claim_retrievals_path = entity_claim_retrievals_path
        self.entity_claim_stances_path = entity_claim_stances_path
        self.topk = topk

    def stance_tweet_retrieval(self, machine_reader_results: List[dict]):
        """
        This function retrieves relevant tweets for claims/premises.
        """
        self.data_items = machine_reader_results
        for i in tqdm (range(len(self.data_items)), desc="Retrieving relevant tweets for each claim..."):
            question = self.data_items[i]["question"]
            question_type = self.data_items[i]["question_type"]
            if question_type == "entity":
                predictions = self.data_items[i]["prediction"].keys()
                for pred in predictions:
                    self.data_items[i]["prediction"][pred]['target_context'] = []
                    premise = build_claim(question, pred)
                    tweet_dict_list = self.retriever.retrieve(premise, topk=self.topk)
                    self.data_items[i]["prediction"][pred]['target_context'].extend(tweet_dict_list)
            elif question_type == "yes-no":
                continue
            else:
                raise Exception("Unknown question type: ", question_type)

        if self.entity_claim_retrievals_path != None:
            logger.info(f"Saving the entity_question_stance_retrievals to {self.entity_claim_retrievals_path}")
            save_jsonl(self.data_items, self.entity_claim_retrievals_path)

    def stance_classification(self, machine_reader_results):
        if self.entity_claim_retrievals_path != None:
            if os.path.exists(self.entity_claim_retrievals_path):
                logger.info(f"Loading entity_question_stance_retrievals from {self.entity_claim_retrievals_path}")
                self.data_items = read_jsonl(self.entity_claim_retrievals_path)
            else:
                self.stance_tweet_retrieval(machine_reader_results)
        else:
                self.stance_tweet_retrieval(machine_reader_results)
        
        stance_detector = StanceDetector(self.stance_detector_name)
        for i in tqdm (range(len(self.data_items)), desc="Doing stance detection for entity claims..."):
            if self.data_items[i]["question_type"] != "entity":
                continue
            question = self.data_items[i]['question']
            logger.debug(f"question: {question}")
                
            for pred in self.data_items[i]['prediction'].keys():
                premise = build_claim(question, pred)
                
                try:
                    target_context = sorted(self.data_items[i]["prediction"][pred]["target_context"], reverse=True, 
                                            key=lambda tweet: tweet['score'])
                except KeyError:
                    self.stance_tweet_retrieval(machine_reader_results)
                    target_context = sorted(self.data_items[i]["prediction"][pred]["target_context"], reverse=True, 
                                            key=lambda tweet: tweet['score'])

                hypo_list = [tc['text'] for tc in target_context]
                premise_list = [premise] * len(hypo_list)
                sentence_pair_df = pd.DataFrame(list(zip(premise_list, hypo_list)), 
                                                columns =['premise', 'hypothesis_text'])
                sentence_pair_df.drop_duplicates(subset=['premise', 'hypothesis_text'], 
                                                keep='first', ignore_index=True, inplace=True)

                logger.debug(f"sentence_pair_df: {sentence_pair_df}")
                
                stance_detector.data_df = sentence_pair_df
                eval_dataloader = stance_detector.get_eval_dataloader()
                stance_predictions, scores = stance_detector.get_model_predictions(eval_dataloader) 
                prediction_labels = [stance_detector.id2label[pred] for pred in stance_predictions]

                candidate_stance_set = set(prediction_labels)
                if "neutral" in candidate_stance_set:
                    candidate_stance_set.remove("neutral")
                if len(candidate_stance_set) == 0:
                    logger.warning(f"WARNING: could not find relevant stance for this question: {question}")
                logger.debug(f"candidate_stance_set: {candidate_stance_set}")

                for stance in ["supporting", "refuting"]:
                    self.data_items[i]["prediction"][pred][stance] = []
                
                # A list of tuples is sorted by their first elements (when first elements are equal, the second one is used, and so on)
                _, sorted_hypo_list, sorted_prediction_labels = zip(*sorted(zip(scores, hypo_list, prediction_labels), reverse=True))

                for hypo, label in zip(sorted_hypo_list, sorted_prediction_labels):
                    if label == "supporting":
                        self.data_items[i]["prediction"][pred]["supporting"].append(hypo)
                    elif label == "refuting":
                        self.data_items[i]["prediction"][pred]["refuting"].append(hypo)
                    else:
                        continue

        if self.entity_claim_stances_path != None:
            logger.info(f"Saving the entity_question_stance_retrievals to {self.entity_claim_stances_path}")
            save_jsonl(self.data_items, self.entity_claim_stances_path)
        return self.data_items


class YesNoClaimStanceMiner(StanceMiner):
    """
    This class contains fuctions 
        to contruct claims using yes-no questions distinct answers; 
        to retrieve relevent tweet for the claims; 
        to prediction relations between claims and their relevent tweets.

    Paras:
        data_jsonl: List[dict]
            could be any jsonl format data that contains yes-no questions.
        retriever: Retriever
            a Retriver instance that is used to retrieve relenvent tweets for claims/premises.
        stance_detector_name: str
            a pretrained stance detection transformer name that is used to initiate a StanceDetector object.
        topk: int
            topk relevant tweets of a claim/premise to retrieve for stance detection.
        yes_no_claim_retrievals_path: str
            file path to save the retrieved tweets.
        yes_no_claim_stances_path: str
            file path to save the stance detected tweets.
    """
    def __init__(self, retriever: Retriever, stance_detector_name: str, topk: int = 100,
                 yes_no_claim_retrievals_path: Optional[str] = None,
                 yes_no_claim_stances_path: Optional[str] = None, 
                 corpus_processed_dir: str = '../data/processed_tweets/'):
        self.retriever = retriever
        self.stance_detector_name = stance_detector_name
        self.yes_no_claim_retrievals_path = yes_no_claim_retrievals_path
        self.yes_no_claim_stances_path = yes_no_claim_stances_path
        self.corpus_processed_dir = corpus_processed_dir
        self.topk = topk
        self.stance_answer_map = {"supporting": "yes", "refuting": "no"}

    def stance_tweet_retrieval(self, data_jsonl: List[dict]):
        """
        This function retrieves relevant tweets for claims/premises.
        """
        self.data_items = data_jsonl
        for i in tqdm (range(len(self.data_items)), desc="Retrieving relevant tweets for each claim..."):
            question = self.data_items[i]["question"]
            question_type = self.data_items[i]["question_type"]
            if question_type == "entity":
                continue
            elif question_type == "yes-no":
                self.data_items[i]['answers']['target_context'] = [] 
                for ans in ["yes", "no"]:
                    premise = build_claim(question, ans)

                    tweet_dict_list = self.retriever.retrieve(premise, topk=int(self.topk/2)) # ranked tweet list
                    self.data_items[i]['answers']['target_context'].extend(tweet_dict_list)
            else:
                raise Exception("Unknown question type: ", question_type)

        if self.yes_no_claim_retrievals_path != None:
            logger.info(f"Saving the yes_no_question_stance_retrievals to {self.yes_no_claim_retrievals_path}")
            save_jsonl(self.data_items, self.yes_no_claim_retrievals_path)

    def golden_stance_tweet_prepare(self, data_jsonl: List[dict]):
        """
        This function use golden stance tweets for intrinsic evalutation.
        """
        self.data_items = data_jsonl
        for i in tqdm (range(len(self.data_items)), desc="Retrieving relevant tweets for each claim..."):
            question_type = self.data_items[i]["question_type"]
            if question_type == "entity":
                continue
            elif question_type == "yes-no":
                self.data_items[i]['answers']['target_context'] = [] 

                for stance in ['supporting', 'refuting']:
                    tweet_dict_list = [{'docid': golden_stance_tweet_id, 'score':100, 'text': get_raw(golden_stance_tweet_id, self.corpus_processed_dir)} for golden_stance_tweet_id in self.data_items[i]['answers'][stance]]
                    self.data_items[i]['answers']['target_context'].extend(tweet_dict_list)
            else:
                raise Exception("Unknown question type: ", question_type)

        if self.yes_no_claim_retrievals_path != None:
            logger.info(f"Saving the yes_no_question_stance_retrievals to {self.yes_no_claim_retrievals_path}")
            save_jsonl(self.data_items, self.yes_no_claim_retrievals_path)

    def stance_classification(self, data_jsonl: List[dict]):
        if self.yes_no_claim_retrievals_path != None:
            if os.path.exists(self.yes_no_claim_retrievals_path):
                logger.info(f"Loading yes_no_question_stance_retrievals from {self.yes_no_claim_retrievals_path}")
                self.data_items = read_jsonl(self.yes_no_claim_retrievals_path)
            else:
                self.stance_tweet_retrieval(data_jsonl)
        else:
                self.stance_tweet_retrieval(data_jsonl)
        
        stance_detector = StanceDetector(self.stance_detector_name)
        for i in tqdm (range(len(self.data_items)), desc="Doing stance detection for yes-no claims..."):
            if self.data_items[i]["question_type"] != "yes-no":
                continue
            question = self.data_items[i]['question']
            logger.debug("question: {question}")
            premise = build_claim(question, 'yes')
            topk_prediction = {}
            ground_truth_answers = YesNoClaimStanceMiner.get_ground_true_answers_from_stance_annotations(self.data_items[i])
            if ground_truth_answers == []:
                logger.warning(f"WARNING: this question has no valid annotation: {question}. Skipping it.")
                continue
            logger.debug(f"supportings: {self.data_items[i]['answers']['supporting']}")
            logger.debug(f"refutings: {self.data_items[i]['answers']['refuting']}")

            target_context = sorted(self.data_items[i]["answers"]["target_context"], 
                                    reverse=True, key=lambda tweet: tweet['score'])[:self.topk]
            
            hypo_list = [tc['text'] for tc in target_context]
            premise_list = [premise] * len(hypo_list)
            sentence_pair_df = pd.DataFrame(list(zip(premise_list, hypo_list)), 
                                            columns =['premise', 'hypothesis_text'])
            sentence_pair_df.drop_duplicates(subset=['premise', 'hypothesis_text'], 
                                            keep='first', ignore_index=True, inplace=True)
            
            logger.debug(f"sentence_pair_df: {sentence_pair_df}")
            
            stance_detector.data_df = sentence_pair_df
            eval_dataloader = stance_detector.get_eval_dataloader()
            stance_predictions, scores = stance_detector.get_model_predictions(eval_dataloader) 
            prediction_labels = [stance_detector.id2label[pred] for pred in stance_predictions]
            
            candidate_answer_set = set(prediction_labels)
            if "neutral" in candidate_answer_set:
                candidate_answer_set.remove("neutral")
            if len(candidate_answer_set) == 0:
                logger.warning(f"WARNING: could not find answer for this question: {question}")
            logger.debug(f"candidate_answer_set: {candidate_answer_set}")
            
            top_predictions = {self.stance_answer_map[ans]: {"evidence": [], "score": []} for ans in candidate_answer_set}
            
            sorted_scores, sorted_hypo_list, sorted_prediction_labels = zip(*sorted(zip(scores, hypo_list, prediction_labels), reverse=True))

            for hypo, score, label in zip(sorted_hypo_list, sorted_scores, sorted_prediction_labels):
                if label == "neutral":
                    continue
                logger.debug(f"score: {score}")

                top_predictions[self.stance_answer_map[label]]["evidence"].append(hypo)
                top_predictions[self.stance_answer_map[label]]["score"].append(str(score))
                
            topk_prediction[f'top{self.topk}'] = top_predictions
            
            logger.debug(f"top_predictions: {top_predictions}")
            self.data_items[i]['prediction'] = topk_prediction

        if self.yes_no_claim_stances_path != None:
            logger.info(f"Saving the yes_no_question_stance_retrievals to {self.yes_no_claim_stances_path}")
            save_jsonl(self.data_items, self.yes_no_claim_stances_path)
        return self.data_items

    @staticmethod
    def get_ground_true_answers_from_stance_annotations(item: dict, 
                                                        stance_answer_map: dict={"supporting": "yes", "refuting": "no"}):
        ground_truth_answers = []
        for stance in ["supporting", "refuting"]:
            if item["answers"][stance] != []:
                ground_truth_answers.append(stance_answer_map[stance])
        return ground_truth_answers
